import streamlit as st
import os
import tempfile

from docloader import load_documents_from_folder
from embedder import create_index, retrieve_docs
from chat_openrouter import ChatOpenRouter
from langchain.prompts import ChatPromptTemplate

st.title("üß≠ Dopasuj kandydata do swoich poglƒÖd√≥w")


with st.sidebar:
    st.title("Dodaj PDFy")
    uploaded_files = st.file_uploader("Dodaj pliki PDF", type=["pdf"], accept_multiple_files=True)

    if uploaded_files:
        with tempfile.TemporaryDirectory() as tmpdir:
            for uploaded_file in uploaded_files:
                file_path = os.path.join(tmpdir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.read())
            documents = load_documents_from_folder(tmpdir)
            st.session_state.documents = documents
            st.session_state.index = create_index(documents)
            st.success(f"Loaded and indexed {len(documents)} documents.")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Porozmawiajmy o poglƒÖdach kandydat√≥w!"}]

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

template = """
Na podstawie poni≈ºszego kontekstu i pytania u≈ºytkownika wska≈º jednego lub kilku kandydat√≥w na prezydenta, kt√≥rych poglƒÖdy sƒÖ najbardziej zgodne z preferencjami u≈ºytkownika. 

Podaj tylko imiona i nazwiska kandydat√≥w oraz kr√≥tko wyja≈õnij, dlaczego zostali zaproponowani. Nie tw√≥rz w≈Çasnych opinii ‚Äì bazuj wy≈ÇƒÖcznie na kontek≈õcie. Je≈õli brak danych ‚Äì napisz: ‚ÄûNie wiem‚Äù.

Pytanie u≈ºytkownika:
{question}

Kontekst:
{context}

Rekomendowani kandydaci:
"""

def answer_with_context(question, index, model):
    top_docs = retrieve_docs(question, index)
    context = "\n\n".join([doc["text"] for doc in top_docs])
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | model
    return chain.invoke({"question": question, "context": context})

def extract_pure_text(response):
    if isinstance(response, dict):
        return response.get("content", str(response))
    elif hasattr(response, "content"):
        return response.content
    else:
        return str(response)

if user_input := st.chat_input("Co jest dla Ciebie wa≈ºne?"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            if "index" in st.session_state:
                response_to_clear = answer_with_context(
                    user_input,
                    st.session_state.index,
                    ChatOpenRouter(model=st.secrets["MODEL"])
                )
                response = extract_pure_text(response_to_clear)
            else:
                response = "Dodaj pliki PDF, aby zapewniƒá kontekst."
            message_placeholder.markdown(response)
        except Exception as e:
            response = f"Error: {e}"
            st.error(response)

    st.session_state.messages.append({"role": "assistant", "content": response})
