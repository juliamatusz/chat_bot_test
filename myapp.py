import streamlit as st
import os
import tempfile

from docloader import load_documents_from_folder
from embedder import create_index, retrieve_docs
from chat_openrouter import ChatOpenRouter
from langchain.prompts import ChatPromptTemplate

st.markdown("### ğŸ—³ï¸ ZnajdÅº kandydata, ktÃ³ry myÅ›li jak Ty")
st.markdown("Porozmawiajmy o Twoich wartoÅ›ciach, a AI dopasuje odpowiednich kandydatÃ³w.")

with st.sidebar:
    st.markdown("### ğŸ“„ ZaÅ‚aduj programy kandydatÃ³w")
    st.caption("KaÅ¼dy plik powinien zawieraÄ‡ program 1 kandydata. Nazwij plik jego imieniem i nazwiskiem, np. `Mentzen_program.pdf`")    uploaded_files = st.file_uploader("Dodaj pliki PDF", type=["pdf"], accept_multiple_files=True)
    if uploaded_files:
        with tempfile.TemporaryDirectory() as tmpdir:
            for uploaded_file in uploaded_files:
                file_path = os.path.join(tmpdir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.read())
            documents = load_documents_from_folder(tmpdir)
            st.session_state.documents = documents
            st.session_state.index = create_index(documents)
            st.success(f"Loaded and indexed {len(documents)} documents.")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Porozmawiajmy o poglÄ…dach kandydatÃ³w!"}]

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

template = """
Na podstawie poniÅ¼szego kontekstu i pytania uÅ¼ytkownika wskaÅ¼ jednego lub kilku kandydatÃ³w na prezydenta, ktÃ³rych poglÄ…dy sÄ… najbardziej zgodne z preferencjami uÅ¼ytkownika. 

Podaj tylko imiona i nazwiska kandydatÃ³w oraz krÃ³tko wyjaÅ›nij, dlaczego zostali zaproponowani. Nie twÃ³rz wÅ‚asnych opinii â€“ bazuj wyÅ‚Ä…cznie na kontekÅ›cie. JeÅ›li brak danych â€“ napisz: â€Nie wiemâ€.

Pytanie uÅ¼ytkownika:
{question}

Kontekst:
{context}

Rekomendowani kandydaci:
"""

def answer_with_context(question, index, model):
    top_docs = retrieve_docs(question, index)
    context = "\n\n".join([doc["text"] for doc in top_docs])
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | model
    return chain.invoke({"question": question, "context": context})

def extract_pure_text(response):
    if isinstance(response, dict):
        return response.get("content", str(response))
    elif hasattr(response, "content"):
        return response.content
    else:
        return str(response)

if user_input := st.chat_input("Jakie poglÄ…dy sÄ… dla Ciebie kluczowe? Napisz np. â€Popieram atom i swobodny dostÄ™p do broniâ€"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            if "index" in st.session_state:
                response_to_clear = answer_with_context(
                    user_input,
                    st.session_state.index,
                    ChatOpenRouter(model=st.secrets["MODEL"])
                )
                response = extract_pure_text(response_to_clear)
            else:
                response = "ğŸ“„ Najpierw zaÅ‚aduj programy kandydatÃ³w w formacie PDF, aby mÃ³c dopasowaÄ‡ odpowiedzi."
            message_placeholder.markdown(response)
        except Exception as e:
            response = f"Error: {e}"
            st.error(response)

    st.session_state.messages.append({"role": "assistant", "content": response})
